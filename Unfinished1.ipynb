{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jjoi8BDqZY6y"
      },
      "outputs": [],
      "source": [
        "import numpy as np \n",
        "import pandas as pd\n",
        "import fasttext\n",
        "import fasttext.util\n",
        "import random\n",
        "from itertools import permutations,combinations\n",
        "from numpy.linalg import norm\n",
        "import math"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ft = fasttext.load_model(r'cc.tr.300.bin')\n"
      ],
      "metadata": {
        "id": "_PA8dSo3aA1g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv(\"words.txt\")\n",
        "liste=np.array(df).flatten()"
      ],
      "metadata": {
        "id": "XKa3b3nuaDjd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_word_vectors(word_list, ft):\n",
        "    \"\"\"\n",
        "    Get word vectors of a word list from a fasttext object\n",
        "    \"\"\"\n",
        "    return np.array(list(map(ft.get_word_vector, word_list)))"
      ],
      "metadata": {
        "id": "glSaXCwRaHrp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vectors = get_word_vectors(liste, ft)\n"
      ],
      "metadata": {
        "id": "0IKqja9saHim"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def cos_similarity_w_matrix(vector, matrix):\n",
        "    \"\"\"\n",
        "    Cosine similarity of a vector to all rows of matrix\n",
        "    \"\"\"\n",
        "    return np.dot(vector, matrix.T) / (np.linalg.norm(vector) * np.linalg.norm(matrix, axis=1))"
      ],
      "metadata": {
        "id": "gEPy1sHzaNI8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def cos_sim_matrix(matrix):\n",
        "    \"\"\"\n",
        "    Pairwise cosine similarity of all rows of matrix\n",
        "    \"\"\"\n",
        "    cs = lambda inp : cos_similarity_w_matrix(inp, matrix)\n",
        "    return np.array(list(map(cs, matrix)))"
      ],
      "metadata": {
        "id": "tDtwxY1taS47"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "word_distances = cos_sim_matrix(vectors)\n"
      ],
      "metadata": {
        "id": "-ema6CPxaYSr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def cosine_sim(vector1, vector2):\n",
        "    dot_product = np.dot(vector1, vector2)\n",
        "    norm_1 = np.linalg.norm(vector1)\n",
        "    norm_2 = np.linalg.norm(vector2)\n",
        "    return dot_product / (norm_1 * norm_2)"
      ],
      "metadata": {
        "id": "cdpfi0z0aSOv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def results(u,show_dict=False,threshold=0.15):\n",
        "    res1=[]\n",
        "    for a,b in combinations(u,2):\n",
        "        if cosine_sim(ft[a],ft[b])<threshold:\n",
        "            res1.append((a,b))    \n",
        "    return len(res1)\n"
      ],
      "metadata": {
        "id": "RDJR4fK1ab-M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def random_dist_creator(word_distances,liste,list_length,threshold=0.14):\n",
        "    temp9=[]\n",
        "\n",
        "    temp9.append(liste[np.argpartition(word_distances[random.randint(0,len(liste)-1)], random.randint(0,10))[random.randint(0,10)]])\n",
        "    \n",
        "    \n",
        "    while True:\n",
        "        a=random.randint(0,len(liste)-1)\n",
        "        b=random.randint(0,10)\n",
        "        index=np.argpartition(word_distances[a], b)[b]\n",
        "        y=cosine_sim(ft[temp9[-1]],ft[liste[index]])   \n",
        "        if threshold>y:    \n",
        "            temp9.append(liste[index])\n",
        "            #print(temp9)\n",
        "        if results(temp9)==(math.comb(list_length, 2)):\n",
        "            break \n",
        "    return temp9\n",
        "\n",
        "\n",
        "    \n",
        "#Returns random sequential distant elements according to some restrictions\n"
      ],
      "metadata": {
        "id": "nx3u1Pjiak6R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "u=random_dist_creator(word_distances,liste,5)\n",
        "u"
      ],
      "metadata": {
        "id": "UZim9Dp2al9K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for a,b in combinations(u,2):\n",
        "    print(cosine_sim(ft[a],ft[b]))\n"
      ],
      "metadata": {
        "id": "NKo5kS81amZi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Semantic Tool Class (STEM-T=> Semantic Tool for Episodic Memory Task)"
      ],
      "metadata": {
        "id": "lUFm9-2wbD_h"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Semantic item class will include turn word to vector (get_word_vectors) cos similiarities (cos_similarity_w_matrix, cos_sim_matrix,cos_sim_matrix, cosine_sim) and furthest elements with regard to list which passes threshold (find_furthest,results) and nearest element (find_nearest)"
      ],
      "metadata": {
        "id": "cJ3bKVhebHpO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class STEM(object):\n",
        "    def __init__(self,word_list,ft,vecotr,matrix,vector1,vector2,u,threshold,word_distances,list_length):\n",
        "        self.word_list=word_list\n",
        "        self.ft= ft\n",
        "        self.vector=vector\n",
        "        self.matrix=matrix\n",
        "        self.vector1=vector1\n",
        "        self.vector2=vector2\n",
        "        self.u=u\n",
        "        self.threshold=threshold\n",
        "        self.word_distances=word_distances\n",
        "        self.list_length=list_length        \n",
        "        \n",
        "    def get_word_vectors(word_list, ft):\n",
        "        return np.array(list(map(ft.get_word_vector, word_list)))\n",
        "    def cos_similarity_w_matrix(vector, matrix):\n",
        "        return np.dot(vector, matrix.T) / (np.linalg.norm(vector) * np.linalg.norm(matrix, axis=1))\n",
        "    def cos_sim_matrix(matrix):\n",
        "        cs = lambda inp : cos_similarity_w_matrix(inp, matrix)\n",
        "        return np.array(list(map(cs, matrix)))\n",
        "    def cos_sim_matrix(matrix):\n",
        "        cs = lambda inp : cos_similarity_w_matrix(inp, matrix)\n",
        "        return np.array(list(map(cs, matrix)))\n",
        "    def inter_cosine_sim(vector1, vector2):\n",
        "        dot_product = np.dot(vector1, vector2)\n",
        "        norm_1 = np.linalg.norm(vector1)\n",
        "        norm_2 = np.linalg.norm(vector2)\n",
        "        return dot_product / (norm_1 * norm_2)\n",
        "    def results(u,threshold=0.15):\n",
        "        res1=[]\n",
        "        for a,b in combinations(u,2):\n",
        "            if cosine_sim(ft[a],ft[b])<threshold:\n",
        "                res1.append((a,b))    \n",
        "        return len(res1)\n",
        "    def random_dist_creator(word_distances,liste,list_length,threshold=0.11):\n",
        "        temp9=[]\n",
        "\n",
        "        temp9.append(liste[np.argpartition(word_distances[random.randint(0,len(liste)-1)], random.randint(0,10))[random.randint(0,10)]])\n",
        "\n",
        "\n",
        "        while True:\n",
        "            a=random.randint(0,len(liste)-1)\n",
        "            b=random.randint(0,10)\n",
        "            index=np.argpartition(word_distances[a], b)[b]\n",
        "            y=cosine_sim(ft[temp9[-1]],ft[liste[index]])   \n",
        "            if threshold>y:    \n",
        "                temp9.append(liste[index])\n",
        "                #print(temp9)\n",
        "            if results(temp9)==(math.comb(list_length, 2)):\n",
        "                break \n",
        "        return temp9\n",
        "\n",
        "\n",
        "    \n",
        "#Returns random sequential distant elements according to some restrictions\n",
        "\n",
        "\n",
        "        return temp9\n",
        "\n",
        "\n",
        "    \n",
        "#Returns random sequential distant elements according to some restrictions\n",
        "\n"
      ],
      "metadata": {
        "id": "jKKF2FdOa4Dw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "d= STEM.inter_cosine_sim(ft[\"kedi\"],ft[\"k√∂pek\"])\n",
        "d"
      ],
      "metadata": {
        "id": "TjiEbsTXbTmz"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}